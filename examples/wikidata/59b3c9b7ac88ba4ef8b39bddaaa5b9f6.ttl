@prefix dcterms: <http://purl.org/dc/terms/> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix schema: <https://schema.org/> .
@prefix sh: <http://www.w3.org/ns/shacl#> .

<https://www.wikidata.org#query-59b3c9b7ac88ba4ef8b39bddaaa5b9f6> a sh:SPARQLExecutable,
    sh:SPARQLSelectExecutable;
  dcterms:isPartOf <https://www.wikidata.org/wiki/Wikidata:Request_a_query/Archive/2020/11>;
  dcterms:license <https://creativecommons.org/licenses/by-sa/4.0/>;
  rdfs:comment "all DOI?Hey, when I try to download the Q-IDs of all DOI registered to Wikidata I always run into timeout. I tried to limit the amount of itmes by reducing the scope to scholarly articles. Is there a way specify for example to small chuncks of items (maybe only Q-ID registered from 2010-2011) that could be combined later on? Thank you!"@en;
  sh:prefixes <https://example.org/to_decide/wikidata_prefixes>;
  sh:select """PREFIX wikibase: <http://wikiba.se/ontology#>
PREFIX wdt: <http://www.wikidata.org/prop/direct/>
PREFIX wd: <http://www.wikidata.org/entity/>
PREFIX bd: <http://www.bigdata.com/rdf#>
SELECT ?item WHERE {
  ?item wdt:P31 wd:Q13442814.
  ?item wdt:P356 ?doi . 
 SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE], ar,be,bg,bn,ca,cs,da,de,el,en,es,et,fa,fi, fr,he,hi,hu,hy,id,it,ja,jv,ko,nb,nl,eo,pa,pl,pt,ro,ru,sh,sk,sr,sv,sw,te,th,tr,uk,yue,vec,vi,zh\"}
                                }""";
  <https://purl.expasy.org/sparql-examples/ontology#bigdata_query> """SELECT ?item WHERE {
  ?item wdt:P31 wd:Q13442814.
  ?item wdt:P356 ?doi . 
 SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE], ar,be,bg,bn,ca,cs,da,de,el,en,es,et,fa,fi, fr,he,hi,hu,hy,id,it,ja,jv,ko,nb,nl,eo,pa,pl,pt,ro,ru,sh,sk,sr,sv,sw,te,th,tr,uk,yue,vec,vi,zh\"}
                                }""";
  <https://purl.expasy.org/sparql-examples/ontology#federatesWith> <http://wikiba.se/ontology#label>;
  schema:target <https://query.wikidata.org/sparql> .
